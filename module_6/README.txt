В ходе EDA были совмещены старые и новые данные для обучения, проведена очистка и унификация данных, обработка пустых значений, дубликатов, проведен минимально достаточный отбор признак с помощью корреляционного анализа. Были созданы новые признаки. Осталось непонятным, почему удаление дубликатов в train (~ 4.9% от общего объема) привело к ухудшению метрики на 0.03, что значительно влияет на итоговое место в leaderboard.

Чтобы работать с моделями в библиотеке LightFm, были созданы разреженные матрицы. Данные в формате COO (координатный формат представления данных). Вместо хранения всех значений, которые включают нулевые значения, сохраняются только ненулевые значения. В COO данные представлены в виде (строка, столбец, значение). Обучение начали с "простой" модели, которая могла бы давать рекомендации к item/user.

Как правило не существует единой рекомендуемой метрики на все случаи жизни и каждый, кто занимается тестированием рекомендательной системы, подбирает её под свои цели. Метрика ROC-AUC наиболее подходит для оценки точности прогнозирования рекомендуемых товаров для увеличения продаж. Тем не менее бывает, что пользователи часто больше интересуются товарами в верхней части списков рекомендаций, но показатель AUC в равной степени зависит от свопов в верхней или нижней части списка рекомендаций. Это может быть недостатком, если мы, в основном, заинтересованы в поиске элементов с наивысшим рейтингом. Решить эту проблему в будущем можно с помощью LAUC (Limited Area Under the Curve). Мера LAUC может быть очень полезна для оценки рекомендательных систем, которые применяются для создания списков товаров высшего качества.

Далее мы провели обучение и предсказание на обогащенных и очищенных данных. Результат целевой метрики практически не изменился по сравнению с "простой" моделью. Следующим шагом стала работа с item_features и эмбедингами. Эмбеддинги – это векторы меньшей размерности в машинном обучении. Они используются для описания текстов, изображений, видео и много другого в поисковых и рекомендательных системах. Эмбеддинги нам нужны, чтобы давать предсказание к каждому товару, а точнее искать наиболее похожие. С помощью user/item_features появляется возможность обойти проблему холодного старта. Мы можем получить информацию о пользователе, например, при регистрации, и использовать эти данные для получения рекомендаций. Если мы используем user/item_features при обучении, то LifhtFM считает, что каждый пользователь и элемент характеризуются одной характеристикой, уникальной для этого пользователя (или элемента). Для быстрого поиска среди большого количества товаров использовали метод ближайших соседей, approximate k-nn, который реализован в библиотеке nmslib. К сожалению, данную модель мы не стали использовать для сабмита, поскольку добавление фичей результат не улучшило (таковы возможные особенности работы LightFM с матрицами item-features).

В целях оптимизации работы модели и достижения лучших результатов возможно также уделить внимание подбору гиперпараметров для LightFM, но в данном проекте эти расчеты не производились.